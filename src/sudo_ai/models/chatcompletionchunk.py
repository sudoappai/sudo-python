"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .chatcompletionchunkchoice import (
    ChatCompletionChunkChoice,
    ChatCompletionChunkChoiceTypedDict,
)
from enum import Enum
from pydantic import model_serializer
from sudo_ai.types import BaseModel, Nullable, OptionalNullable, UNSET, UNSET_SENTINEL
from typing import Any, List, Optional
from typing_extensions import NotRequired, TypedDict


class Object(str, Enum):
    r"""The object type, which is always 'chat.completion.chunk'."""

    CHAT_COMPLETION_CHUNK = "chat.completion.chunk"


class ChatCompletionChunkUsageTypedDict(TypedDict):
    r"""Usage statistics for the completion request. When stream_options.include_usage is set, the final chunk before [DONE] will contain the full usage statistics, and all other chunks will include usage with a null value."""

    completion_tokens: int
    prompt_tokens: int
    total_tokens: int
    completion_tokens_details: NotRequired[Any]
    prompt_tokens_details: NotRequired[Any]


class ChatCompletionChunkUsage(BaseModel):
    r"""Usage statistics for the completion request. When stream_options.include_usage is set, the final chunk before [DONE] will contain the full usage statistics, and all other chunks will include usage with a null value."""

    completion_tokens: int

    prompt_tokens: int

    total_tokens: int

    completion_tokens_details: Optional[Any] = None

    prompt_tokens_details: Optional[Any] = None


class ChatCompletionChunkDataTypedDict(TypedDict):
    id: str
    r"""A unique identifier for the chat completion."""
    object: Object
    r"""The object type, which is always 'chat.completion.chunk'."""
    created: int
    r"""The Unix timestamp (in seconds) of when the chat completion was created."""
    model: str
    r"""The model used for the chat completion."""
    choices: List[ChatCompletionChunkChoiceTypedDict]
    r"""A list of chat completion choices."""
    system_fingerprint: NotRequired[Nullable[str]]
    r"""This fingerprint represents the backend configuration that the model runs with."""
    usage: NotRequired[Nullable[ChatCompletionChunkUsageTypedDict]]
    r"""Usage statistics for the completion request. When stream_options.include_usage is set, the final chunk before [DONE] will contain the full usage statistics, and all other chunks will include usage with a null value."""


class ChatCompletionChunkData(BaseModel):
    id: str
    r"""A unique identifier for the chat completion."""

    object: Object
    r"""The object type, which is always 'chat.completion.chunk'."""

    created: int
    r"""The Unix timestamp (in seconds) of when the chat completion was created."""

    model: str
    r"""The model used for the chat completion."""

    choices: List[ChatCompletionChunkChoice]
    r"""A list of chat completion choices."""

    system_fingerprint: OptionalNullable[str] = UNSET
    r"""This fingerprint represents the backend configuration that the model runs with."""

    usage: OptionalNullable[ChatCompletionChunkUsage] = UNSET
    r"""Usage statistics for the completion request. When stream_options.include_usage is set, the final chunk before [DONE] will contain the full usage statistics, and all other chunks will include usage with a null value."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["system_fingerprint", "usage"]
        nullable_fields = ["system_fingerprint", "usage"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class ChatCompletionChunkTypedDict(TypedDict):
    data: NotRequired[ChatCompletionChunkDataTypedDict]


class ChatCompletionChunk(BaseModel):
    data: Optional[ChatCompletionChunkData] = None
